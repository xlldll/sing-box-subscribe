import json, os, tool, time, requests, sys, importlib, argparse, yaml, ruamel.yaml
import re
from datetime import datetime
from urllib.parse import urlparse
from collections import OrderedDict
from api.app import TEMP_DIR
from parsers.clash2base64 import clash2v2ray
from gh_proxy_helper import set_gh_proxy

parsers_mod = {}
providers = None
color_code = [31, 32, 33, 34, 35, 36, 91, 92, 93, 94, 95, 96]


def loop_color(text):
    text = '\033[1;{color}m{text}\033[0m'.format(color=color_code[0], text=text)
    color_code.append(color_code.pop(0))
    return text


def init_parsers():
    b = os.walk('parsers')
    for path, dirs, files in b:
        for file in files:
            f = os.path.splitext(file)
            if f[1] == '.py':
                parsers_mod[f[0]] = importlib.import_module('parsers.' + f[0])


def get_template():
    template_dir = 'config_template'  # é…ç½®æ¨¡æ¿æ–‡ä»¶å¤¹è·¯å¾„
    template_files = os.listdir(template_dir)  # è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    template_list = [os.path.splitext(file)[0] for file in template_files if
                     file.endswith('.json')]  # ç§»é™¤æ‰©å±•åå¹¶è¿‡æ»¤å‡ºä»¥.jsonç»“å°¾çš„æ–‡ä»¶
    template_list.sort()  # å¯¹æ–‡ä»¶åè¿›è¡Œæ’åº
    return template_list


def load_json(path):
    return json.loads(tool.readFile(path))


def process_subscribes(subscribes):
    nodes = {}
    for subscribe in subscribes:
        if 'enabled' in subscribe and not subscribe['enabled']:
            continue
        if 'sing-box-subscribe-doraemon.vercel.app' in subscribe['url']:
            continue
        _nodes = get_nodes(subscribe['url'])
        if _nodes and len(_nodes) > 0:
            add_prefix(_nodes, subscribe)
            add_emoji(_nodes, subscribe)
            nodefilter(_nodes, subscribe)
            if subscribe.get('subgroup'):
                subscribe['tag'] = subscribe['tag'] + '-' + subscribe['subgroup'] + '-' + 'subgroup'
            if not nodes.get(subscribe['tag']):
                nodes[subscribe['tag']] = []
            nodes[subscribe['tag']] += _nodes
        else:
            print('æ²¡æœ‰åœ¨æ­¤è®¢é˜…ä¸‹æ‰¾åˆ°èŠ‚ç‚¹ï¼Œè·³è¿‡')
    tool.proDuplicateNodeName(nodes)
    return nodes


def nodes_filter(nodes, filters, group):
    """
    filters æ”¯æŒä¸¤ç§å†™æ³•ï¼ˆå¯ä»¥æ··ç”¨ï¼ŒæŒ‰é¡ºåºä¾æ¬¡æ‰§è¡Œï¼‰ï¼š
    1ï¼‰æŒ‰åç§°å…³é”®å­—è¿‡æ»¤ï¼š
       {
         "action": "include" / "exclude",
         "keywords": ["ğŸ‡ºğŸ‡¸|US|ç¾å›½", "HK"]
       }

    2ï¼‰æŒ‰èŠ‚ç‚¹åè®®ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ hysteria2 / trojan / vmess ç­‰ï¼‰ï¼š
       {
         "action": "include" / "exclude",
         "type": ["hysteria2", "trojan"]
       }

    å¯é€‰å­—æ®µï¼š
       "for": ["America", "Asia"]  # åªå¯¹æŒ‡å®š group ç”Ÿæ•ˆ
    """
    for f in filters:
        # å¦‚æœæŒ‡å®šäº† for ä¸”å½“å‰ group ä¸åœ¨å…¶ä¸­ï¼Œè·³è¿‡è¿™æ¡è§„åˆ™
        if f.get('for') and group not in f['for']:
            continue
        # ä¼˜å…ˆæŒ‰ type è¿‡æ»¤
        if 'type' in f:
            nodes = action_types(nodes, f['action'], f['type'])
        else:
            # é€€å›æ—§é€»è¾‘ï¼šæŒ‰å…³é”®å­—è¿‡æ»¤
            nodes = action_keywords(nodes, f['action'], f.get('keywords', []))

    return nodes


def action_keywords(nodes, action, keywords):
    # filter å°†æŒ‰é¡ºåºä¾æ¬¡æ‰§è¡Œ
    # "filter":[
    #   {"action":"include","keywords":[""]},
    #   {"action":"exclude","keywords":[""]}
    # ]
    temp_nodes = []
    flag = False
    if action == 'exclude':
        flag = True

    # å°†å¤šä¸ªå…³é”®å­—ç”¨ | è¿æ¥æˆæ­£åˆ™
    combined_pattern = '|'.join(keywords or [])

    # å¦‚æœå…³é”®å­—ä¸ºç©ºæˆ–åªæœ‰ç©ºç™½ï¼Œåˆ™ä¸åšä»»ä½•è¿‡æ»¤
    if not combined_pattern or combined_pattern.isspace():
        return nodes

    compiled_pattern = re.compile(combined_pattern)

    for node in nodes:
        name = node.get('tag', '')
        match_flag = bool(compiled_pattern.search(name))

        # ç”¨ XOR å†³å®šæ˜¯å¦ä¿ç•™èŠ‚ç‚¹
        # include: match_flag ^ False â†’ åŒ¹é…æ‰ä¿ç•™
        # exclude: match_flag ^ True  â†’ åŒ¹é…åˆ™ä¸¢å¼ƒ
        if match_flag ^ flag:
            temp_nodes.append(node)

    return temp_nodes


def action_types(nodes, action, types):
    """
    æŒ‰èŠ‚ç‚¹åè®®ç±»å‹è¿‡æ»¤ï¼š
    types: ["hysteria2", "trojan", "vmess", ...]
    action:
        - "include": åªä¿ç•™ type åœ¨åˆ—è¡¨ä¸­çš„èŠ‚ç‚¹
        - "exclude": å»æ‰ type åœ¨åˆ—è¡¨ä¸­çš„èŠ‚ç‚¹
    """
    temp_nodes = []
    flag = False
    if action == 'exclude':
        flag = True

    # è§„èŒƒåŒ– type åˆ—è¡¨ï¼Œå…¨éƒ¨å°å†™å»ç©ºç™½
    type_set = {t.strip().lower() for t in (types or []) if t.strip()}
    if not type_set:
        # å¦‚æœæ²¡ç»™æœ‰æ•ˆ typeï¼Œå°±ä¸åšè¿‡æ»¤
        return nodes

    for node in nodes:
        node_type = str(node.get('type', '')).lower()
        match_flag = node_type in type_set

        # åŒæ ·ç”¨ XOR å†³å®šæ˜¯å¦ä¿ç•™
        if match_flag ^ flag:
            temp_nodes.append(node)

    return temp_nodes


def add_prefix(nodes, subscribe):
    if subscribe.get('prefix'):
        for node in nodes:
            node['tag'] = subscribe['prefix'] + node['tag']
            if node.get('detour'):
                node['detour'] = subscribe['prefix'] + node['detour']


def add_emoji(nodes, subscribe):
    if subscribe.get('emoji'):
        for node in nodes:
            node['tag'] = tool.rename(node['tag'])
            if node.get('detour'):
                node['detour'] = tool.rename(node['detour'])


def nodefilter(nodes, subscribe):
    if subscribe.get('ex-node-name'):
        ex_nodename = re.split(r'[,\|]', subscribe['ex-node-name'])
        for exns in ex_nodename:
            for node in nodes[:]:  # éå† nodes çš„å‰¯æœ¬ï¼Œä»¥ä¾¿å®‰å…¨åœ°åˆ é™¤å…ƒç´ 
                if exns in node['tag']:
                    nodes.remove(node)


def get_nodes(url):
    if url.startswith('sub://'):
        url = tool.b64Decode(url[6:]).decode('utf-8')
    urlstr = urlparse(url)
    if not urlstr.scheme:
        try:
            content = tool.b64Decode(url).decode('utf-8')
            data = parse_content(content)
            processed_list = []
            for item in data:
                if isinstance(item, tuple):
                    processed_list.extend([item[0], item[1]])  # å¤„ç†shadowtls
                else:
                    processed_list.append(item)
            return processed_list
        except:
            content = get_content_form_file(url)
    else:
        content = get_content_from_url(url)
    
    
    if type(content) == dict:
        if 'proxies' in content:
            share_links = []
            for proxy in content['proxies']:
                share_links.append(clash2v2ray(proxy))
            data = '\n'.join(share_links)
            data = parse_content(data)
            processed_list = []
            for item in data:
                if isinstance(item, tuple):
                    processed_list.extend([item[0], item[1]])  # å¤„ç†shadowtls
                else:
                    processed_list.append(item)
            return processed_list
        elif 'outbounds' in content:
            outbounds = []
            excluded_types = {"selector", "urltest", "direct", "block", "dns"}
            filtered_outbounds = [outbound for outbound in content['outbounds'] if outbound.get("type") not in excluded_types]
            outbounds.extend(filtered_outbounds)
            return outbounds
    else:
        data = parse_content(content)
        processed_list = []
        for item in data:
            if isinstance(item, tuple):
                processed_list.extend([item[0], item[1]])  # å¤„ç†shadowtls
            else:
                processed_list.append(item)
        return processed_list


def parse_content(content):
    # firstline = tool.firstLine(content)
    # # print(firstline)
    # if not get_parser(firstline):
    #     return None
    nodelist = []
    for t in content.splitlines():
        t = t.strip()
        if len(t) == 0:
            continue
        factory = get_parser(t)
        if not factory:
            continue
        try:
            node = factory(t)
        except Exception as e:  #èŠ‚ç‚¹è§£æå¤±è´¥ï¼Œè·³è¿‡
            pass
        if node:
            node["domain_resolver"] = "dns_direct"
            nodelist.append(node)
    return nodelist


def get_parser(node):
    proto = tool.get_protocol(node)
    if providers.get('exclude_protocol'):
        eps = providers['exclude_protocol'].split(',')
        if len(eps) > 0:
            eps = [protocol.strip() for protocol in eps]
            if 'hy2' in eps:
                index = eps.index('hy2')
                eps[index] = 'hysteria2'
            if proto in eps:
                return None
    if not proto or proto not in parsers_mod.keys():
        return None
    return parsers_mod[proto].parse


def get_content_from_url(url, n=10):
    UA = ''
    print('å¤„ç†: \033[31m' + url + '\033[0m')
    # print('Äang táº£i link Ä‘Äƒng kÃ½: \033[31m' + url + '\033[0m')
    prefixes = ["vmess://", "vless://", "ss://", "ssr://", "trojan://", "tuic://", "hysteria://", "hysteria2://",
                "hy2://", "wg://", "wireguard://", "http2://", "socks://", "socks5://"]
    if any(url.startswith(prefix) for prefix in prefixes):
        response_text = tool.noblankLine(url)
        return response_text
    for subscribe in providers["subscribes"]:
        if 'enabled' in subscribe and not subscribe['enabled']:
            continue
        if subscribe['url'] == url:
            UA = subscribe.get('User-Agent', '')
    response = tool.getResponse(url, custom_user_agent=UA)
    concount = 1
    while concount <= n and not response:
        print('è¿æ¥å‡ºé”™ï¼Œæ­£åœ¨è¿›è¡Œç¬¬ ' + str(concount) + ' æ¬¡é‡è¯•ï¼Œæœ€å¤šé‡è¯• ' + str(n) + ' æ¬¡...')
        response = tool.getResponse(url)
        concount = concount + 1
        time.sleep(1)
    if not response:
        print('è·å–é”™è¯¯ï¼Œè·³è¿‡æ­¤è®¢é˜…')
        print('----------------------------')
        pass
    try:
        response_content = response.content
        response_text = response_content.decode('utf-8-sig')  # utf-8-sig å¯ä»¥å¿½ç•¥ BOM
        #response_encoding = response.encoding
    except:
        return ''
    if response_text.isspace():
        print('æ²¡æœ‰ä»è®¢é˜…é“¾æ¥è·å–åˆ°ä»»ä½•å†…å®¹')
        return None
    if not response_text:
        response = tool.getResponse(url, custom_user_agent='clashmeta')
        response_text = response.text
    if any(response_text.startswith(prefix) for prefix in prefixes):
        response_text = tool.noblankLine(response_text)
        return response_text
    elif 'proxies' in response_text:
        yaml_content = response.content.decode('utf-8')
        response_text_no_tabs = yaml_content.replace('\t', ' ') #fuckU
        yaml = ruamel.yaml.YAML()
        try:
            response_text = dict(yaml.load(response_text_no_tabs))
            return response_text
        except:
            pass
    elif 'outbounds' in response_text:
        try:
            response_text = json.loads(response.text)
            return response_text
        except:
            response_text = re.sub(r'//.*', '', response_text)
            response_text = json.loads(response_text)
            return response_text
    else:
        try:
            response_text = tool.b64Decode(response_text)
            response_text = response_text.decode(encoding="utf-8")
            # response_text = bytes.decode(response_text,encoding=response_encoding)
        except:
            pass
            # traceback.print_exc()
    return response_text


def get_content_form_file(url):
    print('å¤„ç†: \033[31m' + url + '\033[0m')
    # encoding = tool.get_encoding(url)
    file_extension = os.path.splitext(url)[1]  # è·å–æ–‡ä»¶çš„åç¼€å
    if file_extension.lower() == '.yaml':
        with open(url, 'rb') as file:
            content = file.read()
        yaml_data = dict(yaml.safe_load(content))
        share_links = []
        for proxy in yaml_data['proxies']:
            share_links.append(clash2v2ray(proxy))
        node = '\n'.join(share_links)
        processed_list = tool.noblankLine(node)
        return processed_list
    else:
        data = tool.readFile(url)
        data = bytes.decode(data, encoding='utf-8')
        data = tool.noblankLine(data)
        return data


def save_config(path, nodes):
    try:
        if 'auto_backup' in providers and providers['auto_backup']:
            now = datetime.now().strftime('%Y%m%d%H%M%S')
            if os.path.exists(path):
                os.rename(path, f'{path}.{now}.bak')
        if os.path.exists(path):
            os.remove(path)
            print(f"å·²åˆ é™¤æ–‡ä»¶ï¼Œå¹¶é‡æ–°ä¿å­˜ï¼š\033[33m{path}\033[0m")
        else:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¿å­˜ï¼š\033[33m{path}\033[0m")
        tool.saveFile(path, json.dumps(nodes, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"ä¿å­˜é…ç½®æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")
        # å¦‚æœä¿å­˜å‡ºé”™ï¼Œå°è¯•ä½¿ç”¨ config_file_path å†æ¬¡ä¿å­˜
        config_path = json.loads(temp_json_data).get("save_config_path", "config.json")
        CONFIG_FILE_NAME = config_path
        config_file_path = os.path.join('/tmp', CONFIG_FILE_NAME)
        try:
            if os.path.exists(config_file_path):
                os.remove(config_file_path)
                print(f"å·²åˆ é™¤æ–‡ä»¶ï¼Œå¹¶é‡æ–°ä¿å­˜ï¼š\033[33m{config_file_path}\033[0m")
            else:
                print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¿å­˜ï¼š\033[33m{config_file_path}\033[0m")
            tool.saveFile(config_file_path, json.dumps(nodes, indent=2, ensure_ascii=False))
            # print(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ° {config_file_path}")
        except Exception as e:
            os.remove(config_file_path)
            print(f"å·²åˆ é™¤æ–‡ä»¶ï¼š\033[33m{config_file_path}\033[0m")
            print(f"å†æ¬¡ä¿å­˜é…ç½®æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")


def set_proxy_rule_dns(config):
    # dns_template = {
    #     "tag": "remote",
    #     "address": "tls://1.1.1.1",
    #     "detour": ""
    # }
    config_rules = config['route']['rules']
    outbound_dns = []
    dns_rules = config['dns']['rules']
    asod = providers["auto_set_outbounds_dns"]
    for rule in config_rules:
        if rule['outbound'] not in ['block', 'dns-out']:
            if rule['outbound'] != 'direct':
                outbounds_dns_template = \
                    list(filter(lambda server: server['tag'] == asod["proxy"], config['dns']['servers']))[0]
                dns_obj = outbounds_dns_template.copy()
                dns_obj['tag'] = rule['outbound'] + '_dns'
                dns_obj['detour'] = rule['outbound']
                if dns_obj not in outbound_dns:
                    outbound_dns.append(dns_obj)
            if rule.get('type') and rule['type'] == 'logical':
                dns_rule_obj = {
                    'type': 'logical',
                    'mode': rule['mode'],
                    'rules': [],
                    'server': rule['outbound'] + '_dns' if rule['outbound'] != 'direct' else asod["direct"]
                }
                for _rule in rule['rules']:
                    child_rule = pro_dns_from_route_rules(_rule)
                    if child_rule:
                        dns_rule_obj['rules'].append(child_rule)
                if len(dns_rule_obj['rules']) == 0:
                    dns_rule_obj = None
            else:
                dns_rule_obj = pro_dns_from_route_rules(rule)
            if dns_rule_obj:
                dns_rules.append(dns_rule_obj)
    # æ¸…é™¤é‡å¤è§„åˆ™
    _dns_rules = []
    for dr in dns_rules:
        if dr not in _dns_rules:
            _dns_rules.append(dr)
    config['dns']['rules'] = _dns_rules
    config['dns']['servers'].extend(outbound_dns)


def pro_dns_from_route_rules(route_rule):
    dns_route_same_list = ["inbound", "ip_version", "network", "protocol", 'domain', 'domain_suffix', 'domain_keyword',
                           'domain_regex', 'geosite', "source_geoip", "source_ip_cidr", "source_port",
                           "source_port_range", "port", "port_range", "process_name", "process_path", "package_name",
                           "user", "user_id", "clash_mode", "invert"]
    dns_rule_obj = {}
    for key in route_rule:
        if key in dns_route_same_list:
            dns_rule_obj[key] = route_rule[key]
    if len(dns_rule_obj) == 0:
        return None
    if route_rule.get('outbound'):
        dns_rule_obj['server'] = route_rule['outbound'] + '_dns' if route_rule['outbound'] != 'direct' else \
            providers["auto_set_outbounds_dns"]['direct']
    return dns_rule_obj


def pro_node_template(data_nodes, config_outbound, group):
    if config_outbound.get('filter'):
        data_nodes = nodes_filter(data_nodes, config_outbound['filter'], group)
    return [node.get('tag') for node in data_nodes]


def combin_to_config(config, data):
    config_outbounds = config["outbounds"] if config.get("outbounds") else None
    i = 0
    for group in data:
        if 'subgroup' in group:
            i += 1
            for out in config_outbounds:
                if out.get("outbounds"):
                    if out['tag'] == 'Proxy':
                        out["outbounds"] = [out["outbounds"]] if isinstance(out["outbounds"], str) else out["outbounds"]
                        if '{all}' in out["outbounds"]:
                            index_of_all = out["outbounds"].index('{all}')
                            out["outbounds"][index_of_all] = (group.rsplit("-", 1)[0]).rsplit("-", 1)[-1]
                            i += 1
                        else:
                            out["outbounds"].insert(i, (group.rsplit("-", 1)[0]).rsplit("-", 1)[-1])
            new_outbound = {'tag': (group.rsplit("-", 1)[0]).rsplit("-", 1)[-1], 'type': 'selector', 'outbounds': ['{' + group + '}']}
            config_outbounds.insert(-2, new_outbound)
            if 'subgroup' not in group:
                for out in config_outbounds:
                    if out.get("outbounds"):
                        if out['tag'] == 'Proxy':
                            out["outbounds"] = [out["outbounds"]] if isinstance(out["outbounds"], str) else out["outbounds"]
                            out["outbounds"].append('{' + group + '}')
    temp_outbounds = []
    if config_outbounds:
        # è·å– "type": "direct"çš„"tag"å€¼
        direct_item = next((item for item in config_outbounds if item.get('type') == 'direct'), None)
        # æå‰å¤„ç†allæ¨¡æ¿
        for po in config_outbounds:
            # å¤„ç†å‡ºç«™
            if po.get("outbounds"):
                if '{all}' in po["outbounds"]:
                    o1 = []
                    for item in po["outbounds"]:
                        if item.startswith('{') and item.endswith('}'):
                            _item = item[1:-1]
                            if _item == 'all':
                                o1.append(item)
                        else:
                            o1.append(item)
                    po['outbounds'] = o1
                t_o = []
                check_dup = []
                for oo in po["outbounds"]:
                    # é¿å…æ·»åŠ é‡å¤èŠ‚ç‚¹
                    if oo in check_dup:
                        continue
                    else:
                        check_dup.append(oo)
                    # å¤„ç†æ¨¡æ¿
                    if oo.startswith('{') and oo.endswith('}'):
                        oo = oo[1:-1]
                        if data.get(oo):
                            nodes = data[oo]
                            t_o.extend(pro_node_template(nodes, po, oo))
                        else:
                            if oo == 'all':
                                for group in data:
                                    nodes = data[group]
                                    t_o.extend(pro_node_template(nodes, po, group))
                    else:
                        t_o.append(oo)
                if len(t_o) == 0:
                    t_o.append(direct_item['tag'])  # outboundå†…å®¹ä¸ºç©ºæ—¶ æ·»åŠ ç›´è¿ direct
                    print('å‘ç° {} å‡ºç«™ä¸‹çš„èŠ‚ç‚¹æ•°é‡ä¸º 0 ï¼Œä¼šå¯¼è‡´sing-boxæ— æ³•è¿è¡Œï¼Œè¯·æ£€æŸ¥configæ¨¡æ¿æ˜¯å¦æ­£ç¡®ã€‚'.format(
                        po['tag']))
                    """
                    config_path = json.loads(temp_json_data).get("save_config_path", "config.json")
                    CONFIG_FILE_NAME = config_path
                    config_file_path = os.path.join('/tmp', CONFIG_FILE_NAME)
                    if os.path.exists(config_file_path):
                        os.remove(config_file_path)
                        print(f"å·²åˆ é™¤æ–‡ä»¶ï¼š{config_file_path}")
                        # print(f"CÃ¡c táº­p tin Ä‘Ã£ bá»‹ xÃ³a: {config_file_path}")
                    sys.exit()
                    """
                po['outbounds'] = t_o
                if po.get('filter'):
                    del po['filter']
    for group in data:
        temp_outbounds.extend(data[group])
    config['outbounds'] = config_outbounds + temp_outbounds
    # è‡ªåŠ¨é…ç½®è·¯ç”±è§„åˆ™åˆ°dnsè§„åˆ™ï¼Œé¿å…dnsæ³„éœ²
    dns_tags = [server.get('tag') for server in config['dns']['servers']]
    asod = providers.get("auto_set_outbounds_dns")
    if asod and asod.get('proxy') and asod.get('direct') and asod['proxy'] in dns_tags and asod['direct'] in dns_tags:
        set_proxy_rule_dns(config)
    # æå– wireguard ç±»å‹å†…å®¹
    wireguard_items = [item for item in config['outbounds'] if item.get('type') == 'wireguard']
    if wireguard_items:
        endpoints = []
        for item in wireguard_items:
            endpoints.append(item)
        new_config = OrderedDict()
        for key, value in config.items():
            new_config[key] = value
            if key == 'outbounds':  # åœ¨ outbounds åé¢æ’å…¥ endpoint
                new_config['endpoints'] = endpoints
        config = new_config
        # æ›´æ–° outboundsï¼Œç§»é™¤ wireguard ç±»å‹
        config['outbounds'] = [item for item in config['outbounds'] if item.get('type') != 'wireguard']
    return config


def updateLocalConfig(local_host, path):
    header = {
        'Content-Type': 'application/json'
    }
    r = requests.put(local_host + '/configs?force=false', json={"path": path}, headers=header)
    print(r.text)


def display_template(tl):
    print_str = ''
    for i in range(len(tl)):
        print_str += loop_color('{index}ã€{name} '.format(index=i + 1, name=tl[i]))
    print(print_str)


def select_config_template(tl, selected_template_index=None):
    if args.template_index is not None:
        uip = args.template_index
    else:
        uip = input('è¾“å…¥åºå·ï¼Œè½½å…¥å¯¹åº”configæ¨¡æ¿ï¼ˆç›´æ¥å›è½¦é»˜è®¤é€‰ç¬¬ä¸€ä¸ªé…ç½®æ¨¡æ¿ï¼‰ï¼š')
        try:
            if uip == '':
                return 0
            uip = int(uip)
            if uip < 1 or uip > len(tl):
                print('è¾“å…¥äº†é”™è¯¯ä¿¡æ¯ï¼é‡æ–°è¾“å…¥')
                return select_config_template(tl)
            else:
                uip -= 1
        except:
            print('è¾“å…¥äº†é”™è¯¯ä¿¡æ¯ï¼é‡æ–°è¾“å…¥')
            return select_config_template(tl)
    return uip


# è‡ªå®šä¹‰å‡½æ•°ï¼Œç”¨äºè§£æå‚æ•°ä¸º JSON æ ¼å¼
def parse_json(value):
    try:
        return json.loads(value)
    except json.JSONDecodeError:
        raise argparse.ArgumentTypeError(f"Invalid JSON: {value}")

def generate_config_from_providers(providers_data: dict):
    """
    ç»™ Vercel / API ç”¨çš„å°è£…å‡½æ•°ï¼š
    - è¾“å…¥: providers_data (ä» SUB_CONFIG æˆ– URL ä¼ è¿›æ¥çš„ dict)
    - è¾“å‡º: ç”Ÿæˆå¥½çš„ sing-box/clash é…ç½® (dict æˆ– list)
    """
    if not isinstance(providers_data, dict):
        raise ValueError("providers_data å¿…é¡»æ˜¯ dict")

    # è¿™é‡Œæ²¿ç”¨ä½ åŸæ¥çš„å…¨å±€å˜é‡ç”¨æ³•
    global providers
    providers = providers_data

    # åˆå§‹åŒ–è§£æå™¨ï¼ˆå’ŒåŸè„šæœ¬ä¸€æ ·ï¼‰
    init_parsers()

    # 1) å¤„ç†æ¨¡æ¿ config_templateï¼ˆå¦‚æœéœ€è¦ç”¨æ¨¡æ¿ï¼‰
    config = None
    config_template_path = (providers.get("config_template") or "").strip()

    if config_template_path:
        # æœ‰é…ç½®æ¨¡æ¿ï¼šå¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„ï¼Œä¹Ÿå¯ä»¥æ˜¯è¿œç¨‹ URL
        if config_template_path.startswith("http://") or config_template_path.startswith("https://"):
            # è¿œç¨‹æ¨¡æ¿
            resp = requests.get(config_template_path, timeout=10)
            resp.raise_for_status()
            # å°è¯•æŒ‰ JSON è§£æï¼Œä¸è¡Œå†æŒ‰ YAML
            try:
                config = resp.json()
            except Exception:
                try:
                    config = yaml.safe_load(resp.text)
                except Exception as e:
                    raise ValueError(f"è¯»å–è¿œç¨‹æ¨¡æ¿å¤±è´¥: {e}")
        else:
            # æœ¬åœ°æ–‡ä»¶æ¨¡æ¿
            config = load_json(config_template_path)

    # 2) å¤„ç†è®¢é˜…ï¼Œç”ŸæˆèŠ‚ç‚¹
    if "subscribes" not in providers or not providers["subscribes"]:
        raise ValueError("providers ä¸­ç¼ºå°‘ subscribes å­—æ®µï¼Œæˆ–ä¸ºç©º")

    nodes = process_subscribes(providers["subscribes"])

    # 3) åªè¿”å›èŠ‚ç‚¹ï¼Œè¿˜æ˜¯å¥—ç”¨æ¨¡æ¿
    if providers.get("Only-nodes"):
        # åªè¦èŠ‚ç‚¹åˆ—è¡¨
        combined_contents = []
        for sub_tag, contents in nodes.items():
            for content in contents:
                combined_contents.append(content)
        final_config = combined_contents
    else:
        # éœ€è¦å®Œæ•´é…ç½®ï¼Œä½†æ²¡æœ‰æ¨¡æ¿ â†’ ç»™ä¸€ä¸ªæ˜ç¡®æŠ¥é”™ï¼Œè€Œä¸æ˜¯è®© None å»ä¸‹æ ‡
        if config is None:
            raise ValueError(
                "config_template ä¸ºç©ºä¸” Only-nodes ä¸º falseï¼š"
                "åœ¨æ— äº¤äº’ç¯å¢ƒï¼ˆå¦‚ Vercelï¼‰ä¸‹æ— æ³•é€‰æ‹©æ¨¡æ¿ã€‚"
                "è¯·åœ¨ SUB_CONFIG ä¸­æä¾› config_templateï¼Œæˆ–æŠŠ Only-nodes è®¾ä¸º trueã€‚"
            )
        # ç”¨ä½ åŸæ¥çš„ç»„åˆé€»è¾‘
        final_config = combin_to_config(config, nodes)

    # ä¸åœ¨è¿™é‡Œå†™æ–‡ä»¶ï¼Œç›´æ¥è¿”å›ç»™ API
    return final_config

if __name__ == '__main__':
    init_parsers()
    parser = argparse.ArgumentParser()
    parser.add_argument('--temp_json_data', type=parse_json, help='ä¸´æ—¶å†…å®¹')
    parser.add_argument('--template_index', type=int, help='æ¨¡æ¿åºå·')
    parser.add_argument('--gh_proxy_index', type=str, help='githubåŠ é€Ÿé“¾æ¥')
    args = parser.parse_args()
    temp_json_data = args.temp_json_data
    gh_proxy_index = args.gh_proxy_index
    if temp_json_data and temp_json_data != '{}':
        providers = json.loads(temp_json_data)
    else:
        providers = load_json('providers.json')  # åŠ è½½æœ¬åœ° providers.json
    if providers.get('config_template'):
        config_template_path = providers['config_template']
        print('é€‰æ‹©: \033[33m' + config_template_path + '\033[0m')
        response = requests.get(providers['config_template'])
        response.raise_for_status()
        config = response.json()
    else:
        template_list = get_template()
        if len(template_list) < 1:
            print('æ²¡æœ‰æ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶')
            sys.exit()
        display_template(template_list)
        uip = select_config_template(template_list, selected_template_index=args.template_index)
        config_template_path = 'config_template/' + template_list[uip] + '.json'
        print('é€‰æ‹©: \033[33m' + template_list[uip] + '.json\033[0m')
        config = load_json(config_template_path)
    nodes = process_subscribes(providers["subscribes"])

    # å¤„ç†githubåŠ é€Ÿ
    if hasattr(args, 'gh_proxy_index') and str(args.gh_proxy_index).isdigit():
        gh_proxy_index = int(args.gh_proxy_index)
        print(gh_proxy_index)
        urls = [item["url"] for item in config["route"]["rule_set"]]
        new_urls = set_gh_proxy(urls, gh_proxy_index)
        for item, new_url in zip(config["route"]["rule_set"], new_urls):
            item["url"] = new_url


    if providers.get('Only-nodes'):
        combined_contents = []
        for sub_tag, contents in nodes.items():
            # éå†æ¯ä¸ªæœºåœºçš„å†…å®¹
            for content in contents:
                # å°†å†…å®¹æ·»åŠ åˆ°æ–°åˆ—è¡¨ä¸­
                combined_contents.append(content)
        final_config = combined_contents  # åªè¿”å›èŠ‚ç‚¹ä¿¡æ¯
    else:
        final_config = combin_to_config(config, nodes)  # èŠ‚ç‚¹ä¿¡æ¯æ·»åŠ åˆ°æ¨¡æ¿
    save_config(providers["save_config_path"], final_config)
    # updateLocalConfig('http://127.0.0.1:9090',providers['save_config_path'])
